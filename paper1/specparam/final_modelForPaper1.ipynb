{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Final Model for Paper 1\n",
    "\n",
    "**IMPORTANT EDIT ON OCTOBER 29, 2025**\n",
    "_We realized that by doing a clean slate on participants with noisy spectra, we were immensely reducing statistical power. Thus, we decided to openly deal with this noise and keep out spectra for statistical modeling. This is far more robust than imputing and replacing their values with the median of the dataset, especially when we actually HAVE their data_\n",
    "\n",
    "So we for our final model before LASSO, we skipped `remove_subjects_from_finaldf.py`, but still added the dataset from exgm160 go/no-go for the final analysis. You can see that we are now working with **5830** spectra instead of 5826, as seen in `model_analysis.ipynb`\n",
    "\n",
    "~~After we ran `model_analysis.ipynb`, there were a handful of participants left within each cluster who had PSD models removed across experiences.~~\n",
    "\n",
    "~~We want to be able to cleanly analyze data across experiences within each cluster, so that means that the sample size should remain the same, understanding that we would want to look at this through some version of repeated measures statistics.~~\n",
    "\n",
    "~~`remove_subjects_from_finaldf.py`~~\n",
    "So we still had  `../results/specparam/final_model/df_final.pkl`, but this time, we had to remove any unique participants identified during the following 3 phases of exclusion:\n",
    "1. exgm108 and exgm136 because of their failure to follow rules during Go/No-Go\n",
    "2. Any participant that had at least one PSD removed and listed on `removed_models.csv`\n",
    "3. Any participant that had at least one PSD listed on `negative_models.csv`\n",
    "- However, upon further review, all of these participants were already listed on `removed_models.csv`\n",
    "\n",
    "To review documentation on counts and which clusters will not be analyzed, review the Excel spreadsheet _participants_by_cluster_medication_wide.xlsx_ in the Exergame Google Drive folder in  `! Specparam Analysis/Session 1/final_model/`\n",
    "\n",
    "**This python script eventually gave us `df_final_cleaned.pkl`**\n",
    "\n",
    "## `append_additional_spectra.py`\n",
    "When we ran `df_final_cleaned.pkl` through specparam, we noticed that **exgm169_s1_gonogo** was missing. Upon further review of its preprocessed dataset on Google Drive, we noticed that it was missing IC weights. It was re-preprocessed and individually run through the `SpecParamPrep.m` script to produce spectra that were missing for the final model. So we used this python script to append the .mat file of pwelch spectra associated with this dataset to the existing `df_final_cleaned.pkl` file.\n",
    "\n",
    "~~This python script eventually gave us `df_final_cleaned_with_additional_spectra.pkl`~~\n",
    "**UPDATE: The final version works with `df_final_with_additional_spectra`**\n",
    "\n",
    "## UPDATED Analysis Plan\n",
    "Throughout the notebook, we complete the following tasks:\n",
    "1. Fit group spectra\n",
    "2. Create a .csv export for the following metrics:\n",
    "    - All peak metrics (4 columns: cfs, pws, bws, model index)\n",
    "        - Make sure you assign frequency bands based off of cfs value\n",
    "    - All Model Metrics\n",
    "        - Aperiodic parameters (2 columns: offsets, exps [in order models])\n",
    "        - Errors\n",
    "        - R-squared\n",
    "    - **Make sure you use the model index to pull relevant information from `df_final`**\n",
    "3. Plot mean spectra with standard deviation for all 11 clusters. (although we will only be using a select few).\n",
    "    - Plot with aperiodic fit as dotted line (just for record keeping)\n",
    "    - Plot as flattened spectrum\n",
    "        - For these spectra, we will need to plot all participants averaged. However, we will create the following splits:\n",
    "                - Baseline\n",
    "                - All Executive Function\n",
    "                - Shoulder Spectra averaged and Tandem Spectra Average (all participants should have data from all trials)"
   ],
   "id": "b4a6a2eb4a51990c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-01T22:13:22.670930Z",
     "start_time": "2025-11-01T22:13:21.523042Z"
    }
   },
   "source": [
    "# Spectral parameterization imports\n",
    "from specparam import SpectralGroupModel\n",
    "\n",
    "# Import custom function\n",
    "from create_specparam_plots import *"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load Datasets",
   "id": "b5788dd14b4053b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T22:13:25.629274Z",
     "start_time": "2025-11-01T22:13:22.677854Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_pickle('../results/specparam/final_model/df_final_with_additional_spectra.pkl')",
   "id": "fcb267701cb950e9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Fit Spectra",
   "id": "62a79bd81a339fe1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T22:13:33.496596Z",
     "start_time": "2025-11-01T22:13:25.744329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract spectra from final dataframe\n",
    "spectra = np.array([spec for spec in df['spectra']])\n",
    "freqs = np.arange(251)\n",
    "# Initialize and fit new SpectralGroupModel on cleaned data\n",
    "fg = SpectralGroupModel(peak_width_limits=[2, 8], min_peak_height=0.2, peak_threshold=2,\n",
    "                               max_n_peaks=6, verbose=False)\n",
    "freq_range = [1, 55]\n",
    "fg.fit(freqs, spectra, freq_range)\n",
    "fg.print_results()\n",
    "fg.save_report('../results/specparam/final_model/final_groupModel_for_Paper1.pdf')"
   ],
   "id": "77c435f42d9fa809",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================\n",
      "                                                                                                  \n",
      "                                          GROUP RESULTS                                           \n",
      "                                                                                                  \n",
      "                            Number of power spectra in the Group: 5831                            \n",
      "                                                                                                  \n",
      "                        The model was run on the frequency range 1 - 55 Hz                        \n",
      "                                 Frequency Resolution is 1.00 Hz                                  \n",
      "                                                                                                  \n",
      "                              Power spectra were fit without a knee.                              \n",
      "                                                                                                  \n",
      "                                      Aperiodic Fit Values:                                       \n",
      "                        Exponents - Min:  0.064, Max:  2.117, Mean: 0.894                         \n",
      "                                                                                                  \n",
      "                        In total 9675 peaks were extracted from the group                         \n",
      "                                                                                                  \n",
      "                                     Goodness of fit metrics:                                     \n",
      "                            R2s -  Min:  0.562, Max:  0.998, Mean: 0.947                          \n",
      "                         Errors -  Min:  0.015, Max:  0.103, Mean: 0.049                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Export Summary Data as .csv files\n",
    "They will be analyzed further to summarize our data for the manuscript"
   ],
   "id": "3f56dc17b703d489"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Extracting Parameters",
   "id": "f851e6a87e91db11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T22:13:33.536492Z",
     "start_time": "2025-11-01T22:13:33.507838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract peak parameters\n",
    "peaks = fg.get_params('peak_params')  # 4 columns: cfs, pws, bws, model index\n",
    "aps = fg.get_params('aperiodic_params')  # 2 columns: offsets, exps [in order of channels/models]\n",
    "# Extract goodness-of-fit metrics\n",
    "errors = fg.get_params('error')\n",
    "r2s = fg.get_params('r_squared')"
   ],
   "id": "57825dd9a844e5c3",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Peaks Export\n",
    "For each peak that we export, we will need to export its model's following values from `df`:\n",
    "1. subject\n",
    "2. session\n",
    "3. experience\n",
    "4. component\n",
    "5. cluster"
   ],
   "id": "5e38c4804be10ac9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T22:13:33.595738Z",
     "start_time": "2025-11-01T22:13:33.549768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "peaks_export = pd.DataFrame(peaks, columns=['cf', 'pw', 'bw', 'model_ind'])\n",
    "\n",
    "# Convert Model Indices to integers to index from df and MERGE\n",
    "peaks_export['model_ind'] = peaks_export['model_ind'].astype(int)\n",
    "peaks_merged = peaks_export.merge(\n",
    "    df[['subject', 'session', 'experience', 'component', 'cluster']],\n",
    "    left_on='model_ind',\n",
    "    right_index=True,\n",
    "    how='left'\n",
    ")\n",
    "print(\"Method 1 - Using pandas merge:\")\n",
    "print(peaks_merged.head())\n",
    "\n",
    "# Creating a column for frequency bands\n",
    "def assign_freq_band(cf_value):\n",
    "    if 1 <= cf_value < 4:\n",
    "        return \"delta\"\n",
    "    elif 4 <= cf_value < 8:\n",
    "        return \"theta\"\n",
    "    elif 8 <= cf_value < 12:\n",
    "        return \"alpha\"\n",
    "    elif 12 <= cf_value < 20:\n",
    "        return \"low_beta\"\n",
    "    elif 20 <= cf_value < 30:\n",
    "        return \"high_beta\"\n",
    "    elif 30 <= cf_value < 55:\n",
    "        return \"gamma\"\n",
    "    else:\n",
    "        return None  # Default if cf doesn't fall within the specified ranges\n",
    "peaks_merged['freq_band'] = peaks_merged['cf'].apply(assign_freq_band)\n",
    "\n",
    "# Save as .csv file for analysis on R\n",
    "peaks_merged.to_csv('../results/specparam/final_model/peaks.csv', index=False)"
   ],
   "id": "c5b0810dd1bae07c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1 - Using pandas merge:\n",
      "          cf        pw        bw  model_ind  subject session     experience  \\\n",
      "0  19.673625  0.382657  8.000000          0  exgm002      s1  digitbackward   \n",
      "1  10.512218  0.267552  3.274746          1  exgm002      s1   digitforward   \n",
      "2  19.360175  0.496107  8.000000          1  exgm002      s1   digitforward   \n",
      "3  10.031609  0.710193  4.141904          2  exgm002      s1         gonogo   \n",
      "4  18.723401  0.670072  8.000000          2  exgm002      s1         gonogo   \n",
      "\n",
      "   component  cluster  \n",
      "0          5       10  \n",
      "1          5       10  \n",
      "2          5       10  \n",
      "3          5       10  \n",
      "4          5       10  \n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Model Metrics Export\n",
    "Just like above we will need to export each model's following values from `df`:\n",
    "1. subject\n",
    "2. session\n",
    "3. experience\n",
    "4. component\n",
    "5. cluster"
   ],
   "id": "e1af90dc9e6b88ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T22:13:33.640225Z",
     "start_time": "2025-11-01T22:13:33.612103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ensure all arrays are 2D\n",
    "r2s = r2s.reshape(-1, 1)  # Reshape r2s to (12, 1)\n",
    "errors = errors.reshape(-1, 1)  # Reshape errors to (12, 1)\n",
    "\n",
    "# Horizontally stack aperiodic params, R^2, and errors\n",
    "model_metrics = pd.DataFrame(\n",
    "    data=np.hstack([aps, r2s, errors]),  # Horizontally stack arrays\n",
    "    columns=[\"offset\", \"exp\", \"r2\", \"error\"]  # Column names\n",
    ")\n",
    "\n",
    "# Add Model Index for set up for joining with model information\n",
    "model_metrics[\"model_ind\"] = np.arange(len(df), dtype=int)\n",
    "\n",
    "# Add Model Details to model_metric dataframe\n",
    "model_metrics_merged = model_metrics.merge(\n",
    "    df[['subject', 'session', 'experience', 'component', 'cluster']],\n",
    "    left_on='model_ind',\n",
    "    right_index=True,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Write .csv to results folder\n",
    "model_metrics_merged.to_csv('../results/specparam/final_model/model_metrics.csv', index=False)"
   ],
   "id": "81625a9987487edf",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating Plots for each cluster",
   "id": "ef1fa8529b731f8b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T22:13:48.205765Z",
     "start_time": "2025-11-01T22:13:33.660143Z"
    }
   },
   "cell_type": "code",
   "source": "create_all_plots(df, fg) # make sure you edit this function by the time you are analyzing two sessions!",
   "id": "6894235029186e35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting plot generation...\n",
      "Clusters: [np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(12), np.int64(13)]\n",
      "Sessions: ['s1']\n",
      "\n",
      "Processing Cluster 3, Session s1:\n",
      "  Created baseline plots\n",
      "  Created cognitive plots\n",
      "  Created motor plots\n",
      "\n",
      "Processing Cluster 4, Session s1:\n",
      "  Created baseline plots\n",
      "  Created cognitive plots\n",
      "  Created motor plots\n",
      "\n",
      "Processing Cluster 5, Session s1:\n",
      "  Created baseline plots\n",
      "  Created cognitive plots\n",
      "  Created motor plots\n",
      "\n",
      "Processing Cluster 6, Session s1:\n",
      "  Created baseline plots\n",
      "  Created cognitive plots\n",
      "  Created motor plots\n",
      "\n",
      "Processing Cluster 7, Session s1:\n",
      "  Created baseline plots\n",
      "  Created cognitive plots\n",
      "  Created motor plots\n",
      "\n",
      "Processing Cluster 8, Session s1:\n",
      "  Created baseline plots\n",
      "  Created cognitive plots\n",
      "  Created motor plots\n",
      "\n",
      "Processing Cluster 9, Session s1:\n",
      "  Created baseline plots\n",
      "  Created cognitive plots\n",
      "  Created motor plots\n",
      "\n",
      "Processing Cluster 10, Session s1:\n",
      "  Created baseline plots\n",
      "  Created cognitive plots\n",
      "  Created motor plots\n",
      "\n",
      "Processing Cluster 11, Session s1:\n",
      "  Created baseline plots\n",
      "  Created cognitive plots\n",
      "  Created motor plots\n",
      "\n",
      "Processing Cluster 12, Session s1:\n",
      "  Created baseline plots\n",
      "  Created cognitive plots\n",
      "  Created motor plots\n",
      "\n",
      "Processing Cluster 13, Session s1:\n",
      "  Created baseline plots\n",
      "  Created cognitive plots\n",
      "  Created motor plots\n",
      "\n",
      "All plots have been created and saved!\n",
      "Output directory: ../results/specparam/final_model/\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
